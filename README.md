ğŸš€ Sentiment Analysis with BERT (HuggingFace Transformers + IMDB)

This project demonstrates fine-tuning BERT (Bidirectional Encoder Representations from Transformers) for sentiment classification on the IMDB movie review dataset.
It includes a complete end-to-end pipeline:
ğŸ”¥ GPU-accelerated training (CUDA / RTX 3050)
ğŸ“¦ Fine-tuning BERT-base-uncased
ğŸ“Š Evaluation on IMDB dataset
ğŸ’¾ Saving and loading trained model
ğŸŒ FastAPI backend for predictions
ğŸ¨ Streamlit UI for real-time sentiment analysis

This is a professional-level NLP project suitable for:
Academic submissions
Portfolio / GitHub showcase
ML/DL internship applications
Production-ready experimentation

ğŸ“š Table of Contents
Features
Tech Stack
Project Structure
Setup & Installation
Training the Model
Running the API
Running the Web App
Sample API Request
Model Info

âœ¨ Features

Fine-tunes BERT-base-uncased for binary sentiment classification
Uses HuggingFace Transformers for training
Preprocesses IMDB dataset using datasets library
Fully GPU-accelerated (CUDA 12.1)
Exposes prediction API using FastAPI
Beautiful frontend built on Streamlit
Saves the trained model for deployment

ğŸ›  Tech Stack
Component	Technology
NLP Model	BERT-base-uncased
Training Framework	HuggingFace Transformers
Dataset	IMDB (binary classification)
Backend	FastAPI
Frontend	Streamlit
Runtime	Python 3.10
Hardware	NVIDIA RTX 3050 GPU (CUDA)

âš™ï¸ Setup & Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/Naveed05/sentiment-analysis-bert-transformer.git
cd sentiment-analysis-bert-transformer

2ï¸âƒ£ Create virtual environment (optional)
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ§  Training the Model

Run the training script:

python model/train.py


This will:
Download IMDB dataset
Tokenize inputs
Fine-tune BERT for 3 epochs
Save the model at:
model/bert_imdb_model/

ğŸŒ Running the API (FastAPI)
Start the backend server:
uvicorn api.main:app --reload


API runs at:
ğŸ‘‰ http://127.0.0.1:8000

ğŸ”¥ Sample API Request
POST â†’ /predict/

Request:
{
  "text": "The movie was amazing!"
}
Response:
{
  "prediction": 1
}
0 = Negative
1 = Positive

ğŸ¨ Running the Web UI (Streamlit)
streamlit run streamlit_app/app.py


Features:
Text input box
Real-time prediction
Clean UI
Uses FastAPI as backend

ğŸ§¬ Model Info
Model: bert-base-uncased
Parameters: 110M
Epochs: 3
Batch Size: 8
Optimizer: AdamW

Learning Rate: 2e-5
Labels: 0 = Negative, 1 = Positive

ğŸš€ Future Improvements
Add GPT-based explanation generator
Add confidence scoring
Deploy on HuggingFace Spaces

Add Docker container
Use DistilBERT for faster inference
Add training progress visualization

ğŸ‘¤ Author

Mirza Naveed Baig
Deep Learning | NLP | Python | Data Science
GitHub: Naveed05


Future Improvements

Author
